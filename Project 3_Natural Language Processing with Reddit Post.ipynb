{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323b2585",
   "metadata": {},
   "source": [
    "<a id = 'content'><a/>\n",
    "### Content page\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19ac36",
   "metadata": {},
   "source": [
    "<a id = 'section_0'><a/>\n",
    "# 0.0 Function Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bed7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_colwidth' , 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e885124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_scrap(title):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    df_load = []\n",
    "    params = {\n",
    "        'subreddit': title,\n",
    "        'size' : 100,\n",
    "        'before': None\n",
    "    }\n",
    "    for i in range(14):\n",
    "        # Access Reddit API\n",
    "        res = requests.get(url,params)\n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        \n",
    "        \n",
    "        df_new = pd.DataFrame(posts)\n",
    "        df_load.append(df_new)\n",
    "        \n",
    "        # Initiating new time stamp (100th position of the 100 size) for before in params\n",
    "        params['before'] = df_new['created_utc'][99]\n",
    "        \n",
    "        # Extract to CSV\n",
    "        df = pd.concat(df_load, ignore_index = True)\n",
    "        df.to_csv(f'{title}.csv')\n",
    "        time.sleep(20)\n",
    "        print(f'{i+1} Iterations completed')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60c68c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def date_conversion(df , column):\n",
    "\n",
    "    time_value = []\n",
    "    for value in df[column]:\n",
    "        time_value.append(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(value)))\n",
    "        \n",
    "    df[column] = time_value\n",
    "    df[[column]] = df[[column]].astype('datetime64[ns]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56bae9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Iterations completed\n",
      "2 Iterations completed\n",
      "3 Iterations completed\n",
      "4 Iterations completed\n",
      "5 Iterations completed\n",
      "6 Iterations completed\n",
      "7 Iterations completed\n",
      "8 Iterations completed\n",
      "9 Iterations completed\n",
      "10 Iterations completed\n",
      "11 Iterations completed\n",
      "12 Iterations completed\n",
      "13 Iterations completed\n",
      "14 Iterations completed\n"
     ]
    }
   ],
   "source": [
    "# df_fakenews = red_scrap('fakenews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f4ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Iterations completed\n",
      "2 Iterations completed\n",
      "3 Iterations completed\n",
      "4 Iterations completed\n",
      "5 Iterations completed\n",
      "6 Iterations completed\n",
      "7 Iterations completed\n",
      "8 Iterations completed\n",
      "9 Iterations completed\n",
      "10 Iterations completed\n",
      "11 Iterations completed\n",
      "12 Iterations completed\n",
      "13 Iterations completed\n",
      "14 Iterations completed\n"
     ]
    }
   ],
   "source": [
    "# df_politcal_humor = red_scrap('PoliticalHumor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a464f",
   "metadata": {},
   "source": [
    "<a id = 'section_1'><a/>\n",
    "# 1.0 Data Exploration\n",
    "___\n",
    "[(back to top)](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b29d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fakenews = pd.read_csv('fakenews.csv')\n",
    "df_fakenews = df_fakenews[['title' , 'subreddit' , 'created_utc']]\n",
    "\n",
    "# Changing datetime format\n",
    "df_fakenews = date_conversion(df_fakenews , 'created_utc')\n",
    "\n",
    "df_politcal_humor = pd.read_csv('PoliticalHumor.csv')\n",
    "df_politcal_humor = df_politcal_humor[['title' , 'subreddit' , 'created_utc']]\n",
    "\n",
    "# Changing datetime format\n",
    "df_politcal_humor = date_conversion(df_politcal_humor , 'created_utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6500940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Fakenews Datasets : 1400\n",
      "Shape of Fakenews Datasets : (1400, 3)\n",
      "No. of Politcal Humors Datasets : 1400\n",
      "Shape of political Humors Datasets : (1400, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'No. of Fakenews Datasets : {len(df_fakenews)}')\n",
    "print(f'Shape of Fakenews Datasets : {df_fakenews.shape}')\n",
    "\n",
    "print(f'No. of Politcal Humors Datasets : {len(df_politcal_humor)}')\n",
    "print(f'Shape of political Humors Datasets : {df_politcal_humor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459b05",
   "metadata": {},
   "source": [
    "### 1.0 Checking for Duplicates and Null\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "801488d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Duplicate Cell : 0\n",
      "No. of Null Cell : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'No. of Duplicate Cell : {df_fakenews.duplicated().sum()}')\n",
    "print(f'No. of Null Cell : {df_fakenews.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407f8d5",
   "metadata": {},
   "source": [
    "### 1.1 Checking for Data Leakage\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9b31f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1400\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fakenews['title'].str.contains('fake%').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d52b4778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1378\n",
       "True       22\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politcal_humor['title'].str.contains('humor|politic|fun|laugh').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6531ec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magic in a LIVE Broadcast ABC have to see!</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-28 20:52:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC anchor nominated for a Pulitzer</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-26 23:00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Never forget MK Ultra</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-25 22:16:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actual Story Behind the Men Who Stare at Goats</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-24 23:37:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taliban “declaration of Emirate”</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-21 21:54:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title subreddit  \\\n",
       "0      Magic in a LIVE Broadcast ABC have to see!  fakenews   \n",
       "1             ABC anchor nominated for a Pulitzer  fakenews   \n",
       "2                           Never forget MK Ultra  fakenews   \n",
       "3  Actual Story Behind the Men Who Stare at Goats  fakenews   \n",
       "5                Taliban “declaration of Emirate”  fakenews   \n",
       "\n",
       "          created_utc  \n",
       "0 2021-08-28 20:52:06  \n",
       "1 2021-08-26 23:00:36  \n",
       "2 2021-08-25 22:16:04  \n",
       "3 2021-08-24 23:37:24  \n",
       "5 2021-08-21 21:54:16  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fakenews = df_fakenews.loc[~df_fakenews['title'].str.contains('fake')]\n",
    "df_fakenews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4521e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next National Building Project.</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:52:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe people accuse the GOP of being do as I say not as I do hypocrites who only care about taking away the rights of others</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:40:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m starting to think someone is just making stuff now up to see how many dumb conservatives they can get rid of</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:27:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's all send wire coat hangers to the Texas State capital: 1100 Congress Ave, Austin, TX 78701.</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:27:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would tell them it's ironic but they wouldn't know what that means</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:25:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    title  \\\n",
       "0                                                                                                         Next National Building Project.   \n",
       "1  I can't believe people accuse the GOP of being do as I say not as I do hypocrites who only care about taking away the rights of others   \n",
       "2                        I’m starting to think someone is just making stuff now up to see how many dumb conservatives they can get rid of   \n",
       "3                                       Let's all send wire coat hangers to the Texas State capital: 1100 Congress Ave, Austin, TX 78701.   \n",
       "4                                                                    I would tell them it's ironic but they wouldn't know what that means   \n",
       "\n",
       "        subreddit         created_utc  \n",
       "0  PoliticalHumor 2021-09-02 20:52:36  \n",
       "1  PoliticalHumor 2021-09-02 20:40:02  \n",
       "2  PoliticalHumor 2021-09-02 20:27:48  \n",
       "3  PoliticalHumor 2021-09-02 20:27:19  \n",
       "4  PoliticalHumor 2021-09-02 20:25:19  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politcal_humor = df_politcal_humor.loc[~df_politcal_humor['title'].str.contains('humor|politic|fun|laugh')]\n",
    "df_politcal_humor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d8572",
   "metadata": {},
   "source": [
    "### 1.2 Visualing Some Random Text\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d62c317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_fakenews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64bbcad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MY NEWS PUNCH F. DEJAHANG ➜⇢➤27-02-2020 ➽ ➜⇢➤Mainstream Vs. Alternative Media Page 11 MAIN FOLDER ➜⇢ ➽ ➤ https://www.edocr.com/user/drdejahang02...\n",
      "1 Nigel Farage Fake News Lies - Nigel Green deVere CEO\n",
      "2 Imagine my shock.\n",
      "3 It's CNN, goes without saying... but they tried to smear Musk and get destroyed on Twitter.\n",
      "4 Can someone find a news article that complains about the iPhone being a Russian terrorist device, how the Sonic comics scared my some for life, how Minecraft promotes pedofile, how kids are killing people at school because of Nintendo or how Disney is the devil\n",
      "5 I made this in MS Paint, and deep fried it a little bit.\n",
      "6 It's the same picture\n",
      "7 The Artificial Racial Divide with Thomas Sowell\n",
      "8 DEBUNKED: Why this image is not from California's Creek Fire\n",
      "9 Detecting Deep Fakes with a Heartbeat\n"
     ]
    }
   ],
   "source": [
    "random_sentences = random.sample(df_fakenews['title'].to_list() , 10)\n",
    "for index , sentence in enumerate(random_sentences):\n",
    "    print(index , sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e6285de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxation is theft at gunpoint and roads are literally suppressing my free speech\n",
      "they have more in common then you might think\n",
      "New model from the Office of the President, Ida will hit Florida\n",
      "Don't lie\n",
      "Time for a good Belt!\n",
      "If \"big pharma\" is just out to make money ...?\n",
      "Seems strange to me.\n",
      "Fake headline, but pretty sure that it’s a prediction:\n",
      "\"I would build a great wall, and nobody builds walls better than me, believe me, and I’ll build them very inexpensively. I will build a great great wall on our southern border and I’ll have Mexico pay for that wall.\" - Donald Trump's Presidential campaign announcement speech - June 16th, 2015\n",
      "When Wokes and Racists Actually Agree on Everything\n"
     ]
    }
   ],
   "source": [
    "random_sentences = random.sample(df_politcal_humor['title'].to_list() , 10)\n",
    "for sentence in random_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303f6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
