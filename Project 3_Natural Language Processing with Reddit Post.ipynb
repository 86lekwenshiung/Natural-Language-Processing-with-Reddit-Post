{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323b2585",
   "metadata": {},
   "source": [
    "<a id = 'content'><a/>\n",
    "### Content page\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19ac36",
   "metadata": {},
   "source": [
    "<a id = 'section_0'><a/>\n",
    "# 0.0 Function Creation\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bed7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import sleep\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_colwidth' , 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e885124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_scrap(title):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    df_load = []\n",
    "    params = {\n",
    "        'subreddit': title,\n",
    "        'size' : 100,\n",
    "        'before': None\n",
    "    }\n",
    "    for i in range(14):\n",
    "        # Access Reddit API\n",
    "        res = requests.get(url,params)\n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        \n",
    "        \n",
    "        df_new = pd.DataFrame(posts)\n",
    "        df_load.append(df_new)\n",
    "        \n",
    "        # Initiating new time stamp (100th position of the 100 size) for before in params\n",
    "        params['before'] = df_new['created_utc'][99]\n",
    "        \n",
    "        # Extract to CSV\n",
    "        df = pd.concat(df_load, ignore_index = True)\n",
    "        df.to_csv(f'{title}.csv')\n",
    "        time.sleep(20)\n",
    "        print(f'{i+1} Iterations completed')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60c68c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def date_conversion(df , column):\n",
    "\n",
    "    time_value = []\n",
    "    for value in df[column]:\n",
    "        time_value.append(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(value)))\n",
    "        \n",
    "    df[column] = time_value\n",
    "    df[[column]] = df[[column]].astype('datetime64[ns]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56bae9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_fakenews = red_scrap('fakenews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f4ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_politcal_humor = red_scrap('PoliticalHumor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a464f",
   "metadata": {},
   "source": [
    "<a id = 'section_1'><a/>\n",
    "# 1.0 Data Exploration\n",
    "___\n",
    "[(back to top)](#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b29d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fakenews = pd.read_csv('fakenews.csv')\n",
    "df_fakenews = df_fakenews[['title' , 'subreddit' , 'created_utc']]\n",
    "\n",
    "# Changing datetime format\n",
    "df_fakenews = date_conversion(df_fakenews , 'created_utc')\n",
    "\n",
    "df_politcal_humor = pd.read_csv('PoliticalHumor.csv')\n",
    "df_politcal_humor = df_politcal_humor[['title' , 'subreddit' , 'created_utc']]\n",
    "\n",
    "# Changing datetime format\n",
    "df_politcal_humor = date_conversion(df_politcal_humor , 'created_utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6500940b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Fakenews Datasets : 1400\n",
      "Shape of Fakenews Datasets : (1400, 3)\n",
      "No. of Politcal Humors Datasets : 1400\n",
      "Shape of political Humors Datasets : (1400, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'No. of Fakenews Datasets : {len(df_fakenews)}')\n",
    "print(f'Shape of Fakenews Datasets : {df_fakenews.shape}')\n",
    "\n",
    "print(f'No. of Politcal Humors Datasets : {len(df_politcal_humor)}')\n",
    "print(f'Shape of political Humors Datasets : {df_politcal_humor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459b05",
   "metadata": {},
   "source": [
    "### 1.0 Checking for Duplicates and Null\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "801488d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Duplicate Cell : 0\n",
      "No. of Null Cell : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'No. of Duplicate Cell : {df_fakenews.duplicated().sum()}')\n",
    "print(f'No. of Null Cell : {df_fakenews.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407f8d5",
   "metadata": {},
   "source": [
    "### 1.1 Checking for Data Leakage\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9b31f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1400\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fakenews['title'].str.contains('fake%').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d52b4778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1378\n",
       "True       22\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politcal_humor['title'].str.contains('humor|politic|fun|laugh').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6531ec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magic in a LIVE Broadcast ABC have to see!</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-28 20:52:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABC anchor nominated for a Pulitzer</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-26 23:00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Never forget MK Ultra</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-25 22:16:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actual Story Behind the Men Who Stare at Goats</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-24 23:37:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Taliban “declaration of Emirate”</td>\n",
       "      <td>fakenews</td>\n",
       "      <td>2021-08-21 21:54:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title subreddit  \\\n",
       "0      Magic in a LIVE Broadcast ABC have to see!  fakenews   \n",
       "1             ABC anchor nominated for a Pulitzer  fakenews   \n",
       "2                           Never forget MK Ultra  fakenews   \n",
       "3  Actual Story Behind the Men Who Stare at Goats  fakenews   \n",
       "5                Taliban “declaration of Emirate”  fakenews   \n",
       "\n",
       "          created_utc  \n",
       "0 2021-08-28 20:52:06  \n",
       "1 2021-08-26 23:00:36  \n",
       "2 2021-08-25 22:16:04  \n",
       "3 2021-08-24 23:37:24  \n",
       "5 2021-08-21 21:54:16  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fakenews = df_fakenews.loc[~df_fakenews['title'].str.contains('fake')]\n",
    "df_fakenews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4521e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Next National Building Project.</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:52:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can't believe people accuse the GOP of being do as I say not as I do hypocrites who only care about taking away the rights of others</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:40:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I’m starting to think someone is just making stuff now up to see how many dumb conservatives they can get rid of</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:27:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's all send wire coat hangers to the Texas State capital: 1100 Congress Ave, Austin, TX 78701.</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:27:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would tell them it's ironic but they wouldn't know what that means</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>2021-09-02 20:25:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    title  \\\n",
       "0                                                                                                         Next National Building Project.   \n",
       "1  I can't believe people accuse the GOP of being do as I say not as I do hypocrites who only care about taking away the rights of others   \n",
       "2                        I’m starting to think someone is just making stuff now up to see how many dumb conservatives they can get rid of   \n",
       "3                                       Let's all send wire coat hangers to the Texas State capital: 1100 Congress Ave, Austin, TX 78701.   \n",
       "4                                                                    I would tell them it's ironic but they wouldn't know what that means   \n",
       "\n",
       "        subreddit         created_utc  \n",
       "0  PoliticalHumor 2021-09-02 20:52:36  \n",
       "1  PoliticalHumor 2021-09-02 20:40:02  \n",
       "2  PoliticalHumor 2021-09-02 20:27:48  \n",
       "3  PoliticalHumor 2021-09-02 20:27:19  \n",
       "4  PoliticalHumor 2021-09-02 20:25:19  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_politcal_humor = df_politcal_humor.loc[~df_politcal_humor['title'].str.contains('humor|politic|fun|laugh')]\n",
    "df_politcal_humor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d8572",
   "metadata": {},
   "source": [
    "### 1.2 Visualing Some Random Text\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d62c317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1218"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_fakenews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64bbcad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The Fakenews Machine now FULLY Exposed: Anti-Trump Media Collusion to Endorse &amp; Encouraged Riots, Calling Them \"Peaceful\", BACKFIRES, They Now Try Place The Blame ON Trump!\n",
      "1 Reasons Millennials Think News Media is Dividing Our Country!\n",
      "2 New vid\n",
      "3 Groundhog Day\n",
      "4 Do you know the truth about the history of propaganda? (Please see the comments section for more.)\n",
      "5 Unable to cross reference the author name against other credible news sources, outlets, or history\n",
      "6 Washington Post reporter misleads on alcohol price. Note that she cropped out most (but not all) of the green drum\n",
      "7 Did she really say this?\n",
      "8 CNN Tells Viewers to Take Trump’s ‘Hoax’ Comment ‘How You Wish’\n",
      "9 Anti-vaxxers and Russia behind viral 5G COVID conspiracy theory\n"
     ]
    }
   ],
   "source": [
    "random_sentences = random.sample(df_fakenews['title'].to_list() , 10)\n",
    "for index , sentence in enumerate(random_sentences):\n",
    "    print(index , sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e6285de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our chances look grim\n",
      "Trump bad\n",
      "Accurate\n",
      "Neigh\n",
      "😶\n",
      "Democrats have been cleaning up Republican messes for 100 years.\n",
      "All black drivers will be shot before they can get their phones out\n",
      "WAWAWEWA\n",
      "Vanilla ISIS\n",
      "This is getting disgusting.\n"
     ]
    }
   ],
   "source": [
    "random_sentences = random.sample(df_politcal_humor['title'].to_list() , 10)\n",
    "for sentence in random_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc6826c",
   "metadata": {},
   "source": [
    "### 2.0 Data Cleaning and Preprocessing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a560e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33cf2dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "529fa1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snowstorm backlog debunks this article\n",
      "T h e   s n o w s t o r m   b a c k l o g   d e b u n k s   t h i s   a r t i c l e\n",
      "['The', 'snowstorm', 'backlog', 'debunks', 'this', 'article']\n",
      "The snowstorm backlog debunks article\n",
      "-----------------------------------------\n",
      "The Fakenews Machine now FULLY Exposed: Anti-Trump Media Collusion to Endorse &amp; Encouraged Riots, Calling Them \"Peaceful\", BACKFIRES, They Now Try Place The Blame ON Trump!\n",
      "T h e   F a k e n e w s   M a c h i n e   n o w   F U L L Y   E x p o s e d   A n t i T r u m p   M e d i a   C o l l u s i o n   t o   E n d o r s e   a m p   E n c o u r a g e d   R i o t s   C a l l i n g   T h e m   P e a c e f u l   B A C K F I R E S   T h e y   N o w   T r y   P l a c e   T h e   B l a m e   O N   T r u m p\n",
      "['The', 'Fakenews', 'Machine', 'now', 'FULLY', 'Exposed:', 'Anti-Trump', 'Media', 'Collusion', 'to', 'Endorse', '&amp;', 'Encouraged', 'Riots,', 'Calling', 'Them', '\"Peaceful\",', 'BACKFIRES,', 'They', 'Now', 'Try', 'Place', 'The', 'Blame', 'ON', 'Trump!']\n",
      "The Fakenews Machine FULLY Exposed: Anti-Trump Media Collusion Endorse &amp; Encouraged Riots, Calling Them \"Peaceful\", BACKFIRES, They Now Try Place The Blame ON Trump!\n",
      "-----------------------------------------\n",
      "What does help you to judge the credibility of the information you get online?\n",
      "W h a t   d o e s   h e l p   y o u   t o   j u d g e   t h e   c r e d i b i l i t y   o f   t h e   i n f o r m a t i o n   y o u   g e t   o n l i n e\n",
      "['What', 'does', 'help', 'you', 'to', 'judge', 'the', 'credibility', 'of', 'the', 'information', 'you', 'get', 'online?']\n",
      "What help judge credibility information get online?\n",
      "-----------------------------------------\n",
      "Types of humans\n",
      "T y p e s   o f   h u m a n s\n",
      "['Types', 'of', 'humans']\n",
      "Types humans\n",
      "-----------------------------------------\n",
      "Can somebody help me find the video source for this one ?\n",
      "C a n   s o m e b o d y   h e l p   m e   f i n d   t h e   v i d e o   s o u r c e   f o r   t h i s   o n e  \n",
      "['Can', 'somebody', 'help', 'me', 'find', 'the', 'video', 'source', 'for', 'this', 'one', '?']\n",
      "Can somebody help find video source one ?\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. Standardize each example (usually lowercasing + punctuation stripping)\n",
    "2. Split each example into substrings (usually words)\n",
    "3. Recombine substrings into tokens (usually ngrams)\n",
    "'''\n",
    "\n",
    "\n",
    "random_sentences = random.sample(df_fakenews['title'].to_list() , 5)\n",
    "\n",
    "\n",
    "for sentence in random_sentences:\n",
    "    \n",
    "    # Print Before Split\n",
    "    print(sentence)\n",
    "\n",
    "    #Join back without stopwords\n",
    "    sent_split = ' '.join([word for word in sentence if word not in (string.punctuation)])\n",
    "    print(sent_split)    \n",
    "    \n",
    "    # Split the Sentence\n",
    "    sent_split = sentence.split(sep = ' ')\n",
    "    print(sent_split)\n",
    "    \n",
    "\n",
    "    \n",
    "    #Join back without stopwords\n",
    "    joint = ' '.join([word for word in sent_split if word not in (stop_words)])\n",
    "    print(joint)\n",
    "    print('-----------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7227eddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
